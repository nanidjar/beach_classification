{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T21:51:33.087596Z",
     "start_time": "2020-05-30T21:51:24.798768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivan\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T21:51:45.646710Z",
     "start_time": "2020-05-30T21:51:45.396298Z"
    }
   },
   "outputs": [],
   "source": [
    "class survey:\n",
    "\n",
    "    def __init__(self, filepath, parampath, outputpath):\n",
    "\n",
    "        if filepath.endswith('/'):\n",
    "            self.filepath = filepath\n",
    "        else:\n",
    "            self.filepath = filepath + '/'\n",
    "\n",
    "        self.parampath = parampath\n",
    "\n",
    "        if outputpath.endswith('/'):\n",
    "            self.outputpath = outputpath\n",
    "        else:\n",
    "            self.outputpath = outputpath + '/'\n",
    "            \n",
    "        self.features = None\n",
    "\n",
    "    def create_dir(self):\n",
    "\n",
    "        binsize = self.parampath[\"resolution\"]\n",
    "        folders_main = self.outputpath\n",
    "        survey_name = self.parampath[\"survey_name\"]\n",
    "\n",
    "        raw = 'raw'\n",
    "        resolution = 'resolution'\n",
    "        h = '1_histogram'\n",
    "        txtr = '2_rawtexturefeatures'\n",
    "        PCfeat = '3_PCfeatures'\n",
    "        clfs = '4_classifiers'\n",
    "        res_value = str(binsize)\n",
    "\n",
    "        survey_folder = folders_main + survey_name\n",
    "\n",
    "        raw_survey = survey_folder + '/' + raw\n",
    "        res_survey = survey_folder + '/' + resolution + res_value\n",
    "\n",
    "        hist = res_survey + '/' + h\n",
    "        txtfeat = res_survey + '/' + txtr\n",
    "\n",
    "        allfolders = (survey_folder, raw_survey, res_survey, hist, txtfeat)\n",
    "\n",
    "        for elem in allfolders:\n",
    "            try:\n",
    "                os.mkdir(elem)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "    # @jit(parallel=True)\n",
    "    def downsample(self):\n",
    "\n",
    "        inFile = laspy.file.File(self.filepath, mode='r')\n",
    "        # load data attributes\n",
    "        x = inFile.x\n",
    "        y = inFile.y\n",
    "        z = inFile.z\n",
    "        Insty = inFile.intensity\n",
    "        labels = inFile.raw_classification\n",
    "        binsize = self.parampath[\"resolution\"]\n",
    "\n",
    "        # initialize arrays\n",
    "        xbin = np.arange(np.floor(x.min()), np.ceil(x.max()), binsize)\n",
    "        ybin = np.arange(np.floor(y.min()), np.ceil(y.max()), binsize)\n",
    "        count = np.zeros((xbin.shape[0], ybin.shape[0]), dtype=np.uint16)\n",
    "        zsum = np.zeros((xbin.shape[0], ybin.shape[0]))\n",
    "        Itsum = np.zeros((xbin.shape[0], ybin.shape[0]))\n",
    "        labelsum = np.zeros((xbin.shape[0], ybin.shape[0]))\n",
    "\n",
    "        # bin data\n",
    "        for i in range(len(x)):\n",
    "            if ~(labels[i] == 7) & ~(labels[i] == 18):  # ignore noise values\n",
    "                xi = np.digitize(x[i], xbin)\n",
    "                yi = np.digitize(y[i], ybin)\n",
    "                count[xi-1, yi-1] += 1\n",
    "                zsum[xi-1, yi-1] += z[i]\n",
    "                Itsum[xi-1, yi-1] += Insty[i]\n",
    "                labelsum[xi-1, yi-1] += labels[i]\n",
    "            else:\n",
    "                continue\n",
    "            clear_output(wait = True)\n",
    "            print('Downsampling: ', (i/len(x)) * 100, '%',flush = True)\n",
    "\n",
    "        np.seterr(invalid='ignore')\n",
    "\n",
    "        x, y = np.meshgrid(ybin, xbin)\n",
    "        z = zsum / count\n",
    "        I = Itsum / count\n",
    "        labels = labelsum / count\n",
    "\n",
    "        # original labels: water is 9, unclassified is 0, reef is 26\n",
    "        water = labels >= 4.5\n",
    "        unclass = labels < 4.5\n",
    "        labels[unclass] = 1\n",
    "        labels[water] = 2\n",
    "\n",
    "        histpath = self.outputpath + self.parampath[\"survey_name\"] + '/resolution' + str(\n",
    "            self.parampath[\"resolution\"]) + '/1_histogram/' + 'hist' + '.npz'\n",
    "\n",
    "        np.savez(histpath, x=x, y=y, count=count, z=z, I=I, labels=labels)\n",
    "\n",
    "\n",
    "    def gaborkernels(self):\n",
    "\n",
    "        parameters = self.parampath\n",
    "        num_orientations = self.parampath[\"gabor_orient\"]\n",
    "        bandwidths = self.parampath[\"gabor_bw\"]\n",
    "        frequencies = self.parampath[\"gabor_freq\"]\n",
    "\n",
    "        kernels = []\n",
    "\n",
    "        # loop through kernel orientations\n",
    "        for theta in range(int(num_orientations)):\n",
    "            theta = theta / num_orientations * np.pi\n",
    "\n",
    "            # loop through bandwidths\n",
    "            for sigma in bandwidths:\n",
    "\n",
    "                # loop through frequencies\n",
    "                for frequency in frequencies:\n",
    "\n",
    "                    # calculate and take the real part of a gabor wavelet\n",
    "                    kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                                  sigma_x=sigma, sigma_y=sigma))\n",
    "\n",
    "                    # append to kernel list\n",
    "                    kernels.append(kernel)\n",
    "\n",
    "        return kernels\n",
    "\n",
    "    def compute_feats(self, image, kernels):\n",
    "        # \"\"\"Function to calculate the features of an image using a bank of convolution kernels.\n",
    "\n",
    "        # The function takes two inputs.\n",
    "        # 'image' is a 2D numpy array.\n",
    "        # 'kernels' is a list of 2D numpy arrays\n",
    "\n",
    "        # The output will be a numpy array of shape (len(kernels) x 2) where the first column\n",
    "        # contains the mean of each filtered image, and the second column contains the\n",
    "        # variance of each filtered image.\"\"\"\n",
    "\n",
    "        # replace nans with zeros\n",
    "        imagenan = np.isnan(image)\n",
    "        image[imagenan] = 0\n",
    "\n",
    "        # create the feaeture array, one column for mean, and one for variance.\n",
    "        feats = np.zeros((2, len(kernels)), dtype=np.double)\n",
    "\n",
    "        # loop through the gabor wavelet kernels\n",
    "        for k, kernel in enumerate(kernels):\n",
    "\n",
    "            # filter the image using the gabor wavelet\n",
    "            filtered = ndi.convolve(image, kernel, mode='wrap')\n",
    "\n",
    "            # calculate mean and variance of the filtered image, and add each to the feature array\n",
    "            feats[0, k] = np.mean(filtered)\n",
    "            feats[1, k] = np.var(filtered)\n",
    "\n",
    "        return feats\n",
    "\n",
    "    @jit\n",
    "    def blockprocess(self, hists):\n",
    "\n",
    "        parameters = self.parampath\n",
    "\n",
    "        attr_name = parameters[\"texture_attr\"]\n",
    "        step = parameters[\"step_size\"]\n",
    "        block_size = parameters[\"block_size\"]\n",
    "\n",
    "        if attr_name == 'intensity':\n",
    "            attr = hists['I']\n",
    "        elif attr_name == 'height':\n",
    "            attr = hists['z']\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"texture_attr must be 'intensity' or 'height'.\")\n",
    "\n",
    "        # half block size to get indices of block around a pixel.\n",
    "        hb = int(block_size/2)\n",
    "\n",
    "        # initialize numpy arrays for mean and var of each filtered block\n",
    "\n",
    "        num_samples = np.floor(\n",
    "            ((attr.shape[0]-(2*hb))/step))*np.floor(((attr.shape[1]-(2*hb))/step))\n",
    "\n",
    "        kernels = self.gaborkernels()\n",
    "        numkern = len(kernels)\n",
    "\n",
    "        # kernels + x , y, z, I, labels\n",
    "        attr_mean = np.zeros((num_samples.astype(int), numkern+5))\n",
    "        # attr_var = np.zeros_like(attr_mean)\n",
    "\n",
    "        # loop through pixels, starting at half a blocksize away from the edge ( to avoid padding)\n",
    "        # and incremented by step.\n",
    "        i = 0\n",
    "        for xi in range(hb, attr.shape[0]-hb, step):\n",
    "            for yi in range(hb, attr.shape[1]-hb, step):\n",
    "\n",
    "                # if the block has no data in it, just assign the mean and var of that block to zero\n",
    "                if np.isnan(attr[xi, yi]):\n",
    "                    attr_mean[i, 5:] = np.nan\n",
    "\n",
    "                    # attr_var[i, 5:] = np.nan\n",
    "\n",
    "                # calculate features and add mean and var to corresponding numpy arrays.\n",
    "                else:\n",
    "                    coldfeat = self.compute_feats(\n",
    "                        attr[xi-hb:xi+hb, yi-hb:yi+hb], kernels)\n",
    "\n",
    "                    attr_mean[i, 5:] = coldfeat[0, :]\n",
    "                    # attr_var[i, 5:] = coldfeat[1, :]\n",
    "\n",
    "                attr_mean[i, 0] = hists['x'][xi, yi]\n",
    "                attr_mean[i, 1] = hists['y'][xi, yi]\n",
    "                attr_mean[i, 2] = hists['z'][xi, yi]\n",
    "                attr_mean[i, 3] = hists['I'][xi, yi]\n",
    "                attr_mean[i, 4] = hists['labels'][xi, yi]\n",
    "\n",
    "                # attr_var[i, :5] = attr_mean[i, numkern:]\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        return attr_mean\n",
    "\n",
    "    def texture_features(self):\n",
    "\n",
    "        parameters = self.parampath\n",
    "\n",
    "        histspath = self.outputpath + self.parampath[\"survey_name\"] + '/resolution' + str(\n",
    "            self.parampath[\"resolution\"]) + '/1_histogram/' + 'hist' + '.npz'\n",
    "\n",
    "        hists = np.load(histspath)\n",
    "\n",
    "        texturefeats = self.blockprocess(hists)\n",
    "\n",
    "        outfile = self.outputpath + self.parampath[\"survey_name\"] + '/resolution' + \\\n",
    "            str(parameters[\"resolution\"]) + '/2_rawtexturefeatures/' + \\\n",
    "            'hist' + '_res' + \\\n",
    "            str(parameters[\"resolution\"]) + '_raw_feats.npy'\n",
    "\n",
    "        np.savetxt(outfile, texturefeats)\n",
    "\n",
    "    def texture(self):\n",
    "\n",
    "        ##########################################################\n",
    "\n",
    "        num_orientations = self.parampath[\"gabor_orient\"]\n",
    "        bandwidths = self.parampath[\"gabor_bw\"]\n",
    "        frequencies = self.parampath[\"gabor_freq\"]\n",
    "\n",
    "        kernels = []\n",
    "\n",
    "        # loop through kernel orientations\n",
    "        for theta in range(int(num_orientations)):\n",
    "            theta = theta / num_orientations * np.pi\n",
    "\n",
    "            # loop through bandwidths\n",
    "            for sigma in bandwidths:\n",
    "\n",
    "                # loop through frequencies\n",
    "                for frequency in frequencies:\n",
    "\n",
    "                    # calculate and take the real part of a gabor wavelet\n",
    "                    kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                                  sigma_x=sigma, sigma_y=sigma))\n",
    "\n",
    "                    # append to kernel list\n",
    "                    kernels.append(kernel)\n",
    "\n",
    "        ###########################################################\n",
    "\n",
    "        histspath = self.outputpath + self.parampath[\"survey_name\"] + '/resolution' + str(\n",
    "            self.parampath[\"resolution\"]) + '/1_histogram/' + 'hist' + '.npz'\n",
    "\n",
    "        hist = np.load(histspath)\n",
    "\n",
    "        attr = hist['z']\n",
    "\n",
    "        ###############################################################\n",
    "\n",
    "        block_size = self.parampath[\"block_size\"]\n",
    "        step_size = self.parampath[\"step_size\"]\n",
    "\n",
    "        hb = int(block_size/2)\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        num_samples = np.floor(\n",
    "            ((attr.shape[0]-(2*hb))/step_size))*np.floor(((attr.shape[1]-(2*hb))/step_size))\n",
    "        numkern = len(kernels)\n",
    "\n",
    "        # kernels + x , y, z, I, labels\n",
    "\n",
    "        features = np.zeros((num_samples.astype(int), numkern+5))\n",
    "\n",
    "        ###################################################################\n",
    "        i = 0\n",
    "        for xi in range(hb, attr.shape[0]-hb, step_size):\n",
    "            for yi in range(hb, attr.shape[1]-hb, step_size):\n",
    "\n",
    "                if np.isnan(attr[xi, yi]):\n",
    "                    features[i, :] = np.nan\n",
    "                else:\n",
    "                    block = attr[xi-hb:xi+hb, yi-hb:yi+hb]\n",
    "                    features[i, [0, 1, 2, 3, 4]] = [hist['x'][xi, yi], hist['y'][xi, yi],\n",
    "                                                    hist['z'][xi, yi], hist['I'][xi, yi], hist['labels'][xi, yi]]\n",
    "\n",
    "                    for kernel in kernels:\n",
    "                        #print('kernel shape is : ', kernel.shape)\n",
    "                        #print('block shape is : ', block.shape)\n",
    "                        feature = np.mean(ndi.convolve(\n",
    "                            block, kernel, mode='wrap'))\n",
    "                        for j in range(5, len(kernels) + 5):\n",
    "                            features[i, j] = feature\n",
    "                            \n",
    "                            \n",
    "                clear_output(wait = True)            \n",
    "                print('percent complete: ', (i/num_samples) * 100, '%',flush = True)\n",
    "                i += 1\n",
    "\n",
    "        ########################################################################\n",
    "\n",
    "        clean_features = features[~np.isnan(features).any(axis=1)]\n",
    "        cf = clean_features[clean_features[:,4] != 0]\n",
    "        \n",
    "        self.features = cf\n",
    "        \n",
    "        txtrpath = self.outputpath + self.parampath[\"survey_name\"] + '/resolution' + str(\n",
    "            self.parampath[\"resolution\"]) + '/2_rawtexturefeatures/' + 'features' + '.npy'\n",
    "\n",
    "        np.save(txtrpath,cf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:26:54.244721Z",
     "start_time": "2020-05-28T01:26:54.239734Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"survey_name\" : '20190327_00568_00622_NoFilters_Torrey_DelMar',\n",
    "    \"resolution\" : 1,\n",
    "    \n",
    "    \"gabor_orient\" : 4,\n",
    "    \"gabor_bw\" : (1,3),\n",
    "    \"gabor_freq\" : (0.125, 0.25),\n",
    "    \n",
    "    \"block_size\" : 20,\n",
    "    \"step_size\" : 5,\n",
    "    \"texture_attr\" : 'height' # or 'intensity'\n",
    "}\n",
    "\n",
    "lasfile = 'C:/Users/nivan/Documents/CCS_data/20190327_00568_00622_NoFilters_Torrey_DelMar.las'\n",
    "\n",
    "outputdir = 'C:/Users/nivan/Desktop/Beach 2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:26:55.893364Z",
     "start_time": "2020-05-28T01:26:55.889320Z"
    }
   },
   "outputs": [],
   "source": [
    "survey_tdm = survey(lasfile,parameters,outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T23:43:19.742502Z",
     "start_time": "2020-05-24T23:43:19.737127Z"
    }
   },
   "outputs": [],
   "source": [
    "survey_tdm.create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T05:16:08.456159Z",
     "start_time": "2020-05-28T01:27:09.847560Z"
    }
   },
   "outputs": [],
   "source": [
    "features = survey_tdm.texture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T21:51:51.409176Z",
     "start_time": "2020-05-30T21:51:51.405193Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"survey_name\" : '20191209_00568_00636_2304_NoFilters_DelMar',\n",
    "    \"resolution\" : 1,\n",
    "    \n",
    "    \"gabor_orient\" : 4,\n",
    "    \"gabor_bw\" : (1,3),\n",
    "    \"gabor_freq\" : (0.125, 0.25),\n",
    "    \n",
    "    \"block_size\" : 20,\n",
    "    \"step_size\" : 5,\n",
    "    \"texture_attr\" : 'height' # or 'intensity'\n",
    "}\n",
    "\n",
    "lasfile = 'C:/Users/nivan/Documents/CCS_data/20191209_00568_00636_2304_NoFilters_DelMar.las'\n",
    "\n",
    "outputdir = 'C:/Users/nivan/Desktop/Beach 2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-30T21:51:56.654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling:  0.09988781929849344 %\n"
     ]
    }
   ],
   "source": [
    "survey_dm = survey(lasfile,parameters,outputdir)\n",
    "survey_dm.create_dir()\n",
    "survey_dm.downsample()\n",
    "survey_dm.texture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "321.85px",
    "left": "886px",
    "right": "20px",
    "top": "285px",
    "width": "639.9px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
